{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import re\n",
        "\n",
        "stop_words = set()\n",
        "stopwords_directory = '/content/drive/MyDrive/StopWords'\n",
        "for filename in os.listdir(stopwords_directory):\n",
        "    if filename.endswith('.txt'):\n",
        "        with open(os.path.join(stopwords_directory, filename), encoding='ISO-8859-1') as file:\n",
        "            stop_words.update([line.strip() for line in file])\n",
        "\n",
        "positive_words = set(line.strip() for line in open('/content/drive/MyDrive/MasterDictionary/MasterDictionary/positive-words.txt', encoding='ISO-8859-1'))\n",
        "negative_words = set(line.strip() for line in open('/content/drive/MyDrive/MasterDictionary/MasterDictionary/negative-words.txt', encoding='ISO-8859-1'))\n",
        "\n",
        "def extract_text_and_headings(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    for tag in soup(['header', 'footer', 'img', 'iframe', 'media']):\n",
        "        tag.extract()\n",
        "\n",
        "    text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
        "    headings = [h.get_text() for h in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])]\n",
        "    return text, headings\n",
        "\n",
        "def scrape_url(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        text, headings = extract_text_and_headings(response.content)\n",
        "        return text, headings\n",
        "    else:\n",
        "        print(f\"Failed to fetch URL: {url}\")\n",
        "        return None, None\n",
        "\n",
        "def calculate_sentiment(text):\n",
        "    words = word_tokenize(text.lower())\n",
        "\n",
        "    cleaned_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "\n",
        "    pos_score = sum(1 for word in cleaned_words if word in positive_words)\n",
        "    neg_score = sum(1 for word in cleaned_words if word in negative_words)\n",
        "\n",
        "    polarity = (pos_score - neg_score) / ((pos_score + neg_score) + 0.000001)\n",
        "    subjectivity = (pos_score + neg_score) / (len(cleaned_words) + 0.000001)\n",
        "\n",
        "    return pos_score, neg_score, polarity, subjectivity\n",
        "\n",
        "def calculate_readability(text):\n",
        "    words = word_tokenize(text)\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    avg_sentence_length = round(len(words) / len(sentences))\n",
        "    complex_word_count = sum(1 for word in words if len(word) > 2 and word.isalnum() and word not in stop_words)\n",
        "    percentage_complex_words = complex_word_count / len(words)\n",
        "\n",
        "    fog_index = round(0.4 * (avg_sentence_length + percentage_complex_words), 4)\n",
        "    avg_words_per_sentence = round(len(words) / len(sentences))\n",
        "\n",
        "    return avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, complex_word_count\n",
        "\n",
        "def calculate_syllable_per_word(text):\n",
        "    words = word_tokenize(text)\n",
        "    total_syllables = 0\n",
        "\n",
        "    for word in words:\n",
        "        word = re.sub(r'[.,!?]', '', word)\n",
        "        if len(word) > 2 and word.isalnum() and word not in stop_words:\n",
        "            syllables = 0\n",
        "            vowels = 'aeiouAEIOU'\n",
        "            prev_char = None\n",
        "            for char in word:\n",
        "                if char in vowels and (prev_char is None or prev_char not in vowels):\n",
        "                    syllables += 1\n",
        "                prev_char = char\n",
        "            if word.endswith('e'):\n",
        "                syllables -= 1\n",
        "            if syllables == 0:\n",
        "                syllables = 1\n",
        "            total_syllables += syllables\n",
        "\n",
        "    avg_syllables_per_word = total_syllables / len(words)\n",
        "    return avg_syllables_per_word\n",
        "\n",
        "def calculate_personal_pronouns(text):\n",
        "    personal_pronouns = re.findall(r'\\b(I|we|my|ours|us)\\b', text)\n",
        "    return len(personal_pronouns)\n",
        "\n",
        "def calculate_avg_word_length(text):\n",
        "    words = word_tokenize(text)\n",
        "    total_characters = sum(len(word) for word in words)\n",
        "    avg_word_length = total_characters / len(words)\n",
        "    return avg_word_length\n",
        "\n",
        "def main():\n",
        "    excel_file = '/content/Input.xlsx'\n",
        "    df = pd.read_excel(excel_file)\n",
        "    text_files_directory = 'extracted_text'\n",
        "    os.makedirs(text_files_directory, exist_ok=True)\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        url_id = row['URL_ID']\n",
        "        url = row['URL']\n",
        "\n",
        "        text, headings = scrape_url(url.strip())\n",
        "\n",
        "        if text:\n",
        "            text_filename = os.path.join(text_files_directory, f'text_{url_id}.txt')\n",
        "            with open(text_filename, 'w', encoding='utf-8') as text_file:\n",
        "                text_file.write(text)\n",
        "\n",
        "            pos_score, neg_score, polarity, subjectivity = calculate_sentiment(text)\n",
        "            avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, complex_word_count = calculate_readability(text)\n",
        "            word_count = len(word_tokenize(text))\n",
        "            syllable_per_word = calculate_syllable_per_word(text)\n",
        "            personal_pronouns = calculate_personal_pronouns(text)\n",
        "            avg_word_length = calculate_avg_word_length(text)\n",
        "\n",
        "            df.at[index, 'POSITIVE SCORE'] = pos_score\n",
        "            df.at[index, 'NEGATIVE SCORE'] = neg_score\n",
        "            df.at[index, 'POLARITY SCORE'] = polarity\n",
        "            df.at[index, 'SUBJECTIVITY SCORE'] = subjectivity\n",
        "            df.at[index, 'AVG SENTENCE LENGTH'] = avg_sentence_length\n",
        "            df.at[index, 'PERCENTAGE OF COMPLEX WORDS'] = percentage_complex_words\n",
        "            df.at[index, 'FOG INDEX'] = fog_index\n",
        "            df.at[index, 'AVG NUMBER OF WORDS PER SENTENCE'] = avg_words_per_sentence\n",
        "            df.at[index, 'COMPLEX WORD COUNT'] = complex_word_count\n",
        "            df.at[index, 'WORD COUNT'] = word_count\n",
        "            df.at[index, 'SYLLABLE PER WORD'] = syllable_per_word\n",
        "            df.at[index, 'PERSONAL PRONOUNS'] = personal_pronouns\n",
        "            df.at[index, 'AVG WORD LENGTH'] = round(avg_word_length, 4)\n",
        "\n",
        "            print(f\"Scores calculated and updated for URL ID {url_id}.\")\n",
        "            print(f\"Extracted text saved to {text_filename}\")\n",
        "\n",
        "    output_file = 'output.xlsx'\n",
        "    df.to_excel(output_file, index=False)\n",
        "    print(\"Results saved to\", output_file)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dewFFOgVPPu8",
        "outputId": "b7432454-d6f1-487c-e405-2b0f8d0f282c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores calculated and updated for URL ID 123.0.\n",
            "Extracted text saved to extracted_text/text_123.0.txt\n",
            "Scores calculated and updated for URL ID 321.0.\n",
            "Extracted text saved to extracted_text/text_321.0.txt\n",
            "Scores calculated and updated for URL ID 2345.0.\n",
            "Extracted text saved to extracted_text/text_2345.0.txt\n",
            "Scores calculated and updated for URL ID 4321.0.\n",
            "Extracted text saved to extracted_text/text_4321.0.txt\n",
            "Scores calculated and updated for URL ID 432.0.\n",
            "Extracted text saved to extracted_text/text_432.0.txt\n",
            "Scores calculated and updated for URL ID 2893.8.\n",
            "Extracted text saved to extracted_text/text_2893.8.txt\n",
            "Scores calculated and updated for URL ID 3355.6.\n",
            "Extracted text saved to extracted_text/text_3355.6.txt\n",
            "Scores calculated and updated for URL ID 3817.4.\n",
            "Extracted text saved to extracted_text/text_3817.4.txt\n",
            "Scores calculated and updated for URL ID 4279.2.\n",
            "Extracted text saved to extracted_text/text_4279.2.txt\n",
            "Scores calculated and updated for URL ID 4741.0.\n",
            "Extracted text saved to extracted_text/text_4741.0.txt\n",
            "Scores calculated and updated for URL ID 5202.8.\n",
            "Extracted text saved to extracted_text/text_5202.8.txt\n",
            "Scores calculated and updated for URL ID 5664.6.\n",
            "Extracted text saved to extracted_text/text_5664.6.txt\n",
            "Scores calculated and updated for URL ID 6126.4.\n",
            "Extracted text saved to extracted_text/text_6126.4.txt\n",
            "Scores calculated and updated for URL ID 6588.2.\n",
            "Extracted text saved to extracted_text/text_6588.2.txt\n",
            "Scores calculated and updated for URL ID 7050.0.\n",
            "Extracted text saved to extracted_text/text_7050.0.txt\n",
            "Scores calculated and updated for URL ID 7511.8.\n",
            "Extracted text saved to extracted_text/text_7511.8.txt\n",
            "Scores calculated and updated for URL ID 7973.6.\n",
            "Extracted text saved to extracted_text/text_7973.6.txt\n",
            "Scores calculated and updated for URL ID 8435.4.\n",
            "Extracted text saved to extracted_text/text_8435.4.txt\n",
            "Scores calculated and updated for URL ID 8897.2.\n",
            "Extracted text saved to extracted_text/text_8897.2.txt\n",
            "Scores calculated and updated for URL ID 9359.0.\n",
            "Extracted text saved to extracted_text/text_9359.0.txt\n",
            "Scores calculated and updated for URL ID 9820.8.\n",
            "Extracted text saved to extracted_text/text_9820.8.txt\n",
            "Scores calculated and updated for URL ID 10282.6.\n",
            "Extracted text saved to extracted_text/text_10282.6.txt\n",
            "Scores calculated and updated for URL ID 10744.4.\n",
            "Extracted text saved to extracted_text/text_10744.4.txt\n",
            "Scores calculated and updated for URL ID 11206.2.\n",
            "Extracted text saved to extracted_text/text_11206.2.txt\n",
            "Failed to fetch URL: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
            "Scores calculated and updated for URL ID 12129.8.\n",
            "Extracted text saved to extracted_text/text_12129.8.txt\n",
            "Scores calculated and updated for URL ID 12591.6.\n",
            "Extracted text saved to extracted_text/text_12591.6.txt\n",
            "Scores calculated and updated for URL ID 13053.4.\n",
            "Extracted text saved to extracted_text/text_13053.4.txt\n",
            "Scores calculated and updated for URL ID 13515.2.\n",
            "Extracted text saved to extracted_text/text_13515.2.txt\n",
            "Scores calculated and updated for URL ID 13977.0.\n",
            "Extracted text saved to extracted_text/text_13977.0.txt\n",
            "Scores calculated and updated for URL ID 14438.8.\n",
            "Extracted text saved to extracted_text/text_14438.8.txt\n",
            "Scores calculated and updated for URL ID 14900.6.\n",
            "Extracted text saved to extracted_text/text_14900.6.txt\n",
            "Scores calculated and updated for URL ID 15362.4.\n",
            "Extracted text saved to extracted_text/text_15362.4.txt\n",
            "Scores calculated and updated for URL ID 15824.2.\n",
            "Extracted text saved to extracted_text/text_15824.2.txt\n",
            "Scores calculated and updated for URL ID 16286.0.\n",
            "Extracted text saved to extracted_text/text_16286.0.txt\n",
            "Scores calculated and updated for URL ID 16747.8.\n",
            "Extracted text saved to extracted_text/text_16747.8.txt\n",
            "Scores calculated and updated for URL ID 17209.6.\n",
            "Extracted text saved to extracted_text/text_17209.6.txt\n",
            "Failed to fetch URL: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
            "Scores calculated and updated for URL ID 18133.2.\n",
            "Extracted text saved to extracted_text/text_18133.2.txt\n",
            "Scores calculated and updated for URL ID 18595.0.\n",
            "Extracted text saved to extracted_text/text_18595.0.txt\n",
            "Scores calculated and updated for URL ID 19056.8.\n",
            "Extracted text saved to extracted_text/text_19056.8.txt\n",
            "Scores calculated and updated for URL ID 19518.6.\n",
            "Extracted text saved to extracted_text/text_19518.6.txt\n",
            "Scores calculated and updated for URL ID 19980.4.\n",
            "Extracted text saved to extracted_text/text_19980.4.txt\n",
            "Scores calculated and updated for URL ID 20442.2.\n",
            "Extracted text saved to extracted_text/text_20442.2.txt\n",
            "Scores calculated and updated for URL ID 20904.0.\n",
            "Extracted text saved to extracted_text/text_20904.0.txt\n",
            "Scores calculated and updated for URL ID 21365.8.\n",
            "Extracted text saved to extracted_text/text_21365.8.txt\n",
            "Scores calculated and updated for URL ID 21827.6.\n",
            "Extracted text saved to extracted_text/text_21827.6.txt\n",
            "Scores calculated and updated for URL ID 22289.4.\n",
            "Extracted text saved to extracted_text/text_22289.4.txt\n",
            "Scores calculated and updated for URL ID 22751.2.\n",
            "Extracted text saved to extracted_text/text_22751.2.txt\n",
            "Scores calculated and updated for URL ID 23213.0.\n",
            "Extracted text saved to extracted_text/text_23213.0.txt\n",
            "Scores calculated and updated for URL ID 23674.8.\n",
            "Extracted text saved to extracted_text/text_23674.8.txt\n",
            "Scores calculated and updated for URL ID 24136.6.\n",
            "Extracted text saved to extracted_text/text_24136.6.txt\n",
            "Scores calculated and updated for URL ID 24598.4.\n",
            "Extracted text saved to extracted_text/text_24598.4.txt\n",
            "Scores calculated and updated for URL ID 25060.2.\n",
            "Extracted text saved to extracted_text/text_25060.2.txt\n",
            "Scores calculated and updated for URL ID 25522.0.\n",
            "Extracted text saved to extracted_text/text_25522.0.txt\n",
            "Scores calculated and updated for URL ID 25983.8.\n",
            "Extracted text saved to extracted_text/text_25983.8.txt\n",
            "Scores calculated and updated for URL ID 26445.6.\n",
            "Extracted text saved to extracted_text/text_26445.6.txt\n",
            "Scores calculated and updated for URL ID 26907.4.\n",
            "Extracted text saved to extracted_text/text_26907.4.txt\n",
            "Scores calculated and updated for URL ID 27369.2.\n",
            "Extracted text saved to extracted_text/text_27369.2.txt\n",
            "Scores calculated and updated for URL ID 27831.0.\n",
            "Extracted text saved to extracted_text/text_27831.0.txt\n",
            "Scores calculated and updated for URL ID 28292.8.\n",
            "Extracted text saved to extracted_text/text_28292.8.txt\n",
            "Scores calculated and updated for URL ID 28754.6.\n",
            "Extracted text saved to extracted_text/text_28754.6.txt\n",
            "Scores calculated and updated for URL ID 29216.4.\n",
            "Extracted text saved to extracted_text/text_29216.4.txt\n",
            "Scores calculated and updated for URL ID 29678.2.\n",
            "Extracted text saved to extracted_text/text_29678.2.txt\n",
            "Scores calculated and updated for URL ID 30140.0.\n",
            "Extracted text saved to extracted_text/text_30140.0.txt\n",
            "Scores calculated and updated for URL ID 30601.8.\n",
            "Extracted text saved to extracted_text/text_30601.8.txt\n",
            "Scores calculated and updated for URL ID 31063.6.\n",
            "Extracted text saved to extracted_text/text_31063.6.txt\n",
            "Scores calculated and updated for URL ID 31525.4.\n",
            "Extracted text saved to extracted_text/text_31525.4.txt\n",
            "Scores calculated and updated for URL ID 31987.2.\n",
            "Extracted text saved to extracted_text/text_31987.2.txt\n",
            "Scores calculated and updated for URL ID 32449.0.\n",
            "Extracted text saved to extracted_text/text_32449.0.txt\n",
            "Scores calculated and updated for URL ID 32910.8.\n",
            "Extracted text saved to extracted_text/text_32910.8.txt\n",
            "Scores calculated and updated for URL ID 33372.6.\n",
            "Extracted text saved to extracted_text/text_33372.6.txt\n",
            "Scores calculated and updated for URL ID 33834.4.\n",
            "Extracted text saved to extracted_text/text_33834.4.txt\n",
            "Scores calculated and updated for URL ID 34296.2.\n",
            "Extracted text saved to extracted_text/text_34296.2.txt\n",
            "Scores calculated and updated for URL ID 34758.0.\n",
            "Extracted text saved to extracted_text/text_34758.0.txt\n",
            "Scores calculated and updated for URL ID 35219.8.\n",
            "Extracted text saved to extracted_text/text_35219.8.txt\n",
            "Scores calculated and updated for URL ID 35681.6.\n",
            "Extracted text saved to extracted_text/text_35681.6.txt\n",
            "Scores calculated and updated for URL ID 36143.4.\n",
            "Extracted text saved to extracted_text/text_36143.4.txt\n",
            "Scores calculated and updated for URL ID 36605.2.\n",
            "Extracted text saved to extracted_text/text_36605.2.txt\n",
            "Scores calculated and updated for URL ID 37067.0.\n",
            "Extracted text saved to extracted_text/text_37067.0.txt\n",
            "Scores calculated and updated for URL ID 37528.8.\n",
            "Extracted text saved to extracted_text/text_37528.8.txt\n",
            "Scores calculated and updated for URL ID 37990.6.\n",
            "Extracted text saved to extracted_text/text_37990.6.txt\n",
            "Scores calculated and updated for URL ID 38452.4.\n",
            "Extracted text saved to extracted_text/text_38452.4.txt\n",
            "Scores calculated and updated for URL ID 38914.2.\n",
            "Extracted text saved to extracted_text/text_38914.2.txt\n",
            "Scores calculated and updated for URL ID 39376.0.\n",
            "Extracted text saved to extracted_text/text_39376.0.txt\n",
            "Scores calculated and updated for URL ID 39837.8.\n",
            "Extracted text saved to extracted_text/text_39837.8.txt\n",
            "Scores calculated and updated for URL ID 40299.6.\n",
            "Extracted text saved to extracted_text/text_40299.6.txt\n",
            "Scores calculated and updated for URL ID 40761.4.\n",
            "Extracted text saved to extracted_text/text_40761.4.txt\n",
            "Scores calculated and updated for URL ID 41223.2.\n",
            "Extracted text saved to extracted_text/text_41223.2.txt\n",
            "Scores calculated and updated for URL ID 41685.0.\n",
            "Extracted text saved to extracted_text/text_41685.0.txt\n",
            "Scores calculated and updated for URL ID 42146.8.\n",
            "Extracted text saved to extracted_text/text_42146.8.txt\n",
            "Scores calculated and updated for URL ID 42608.6.\n",
            "Extracted text saved to extracted_text/text_42608.6.txt\n",
            "Scores calculated and updated for URL ID 43070.4.\n",
            "Extracted text saved to extracted_text/text_43070.4.txt\n",
            "Scores calculated and updated for URL ID 43532.2.\n",
            "Extracted text saved to extracted_text/text_43532.2.txt\n",
            "Scores calculated and updated for URL ID 43994.0.\n",
            "Extracted text saved to extracted_text/text_43994.0.txt\n",
            "Scores calculated and updated for URL ID 44455.8.\n",
            "Extracted text saved to extracted_text/text_44455.8.txt\n",
            "Scores calculated and updated for URL ID 44917.6.\n",
            "Extracted text saved to extracted_text/text_44917.6.txt\n",
            "Scores calculated and updated for URL ID 45379.4.\n",
            "Extracted text saved to extracted_text/text_45379.4.txt\n",
            "Scores calculated and updated for URL ID 45841.2.\n",
            "Extracted text saved to extracted_text/text_45841.2.txt\n",
            "Scores calculated and updated for URL ID 46303.0.\n",
            "Extracted text saved to extracted_text/text_46303.0.txt\n",
            "Scores calculated and updated for URL ID 46764.8.\n",
            "Extracted text saved to extracted_text/text_46764.8.txt\n",
            "Scores calculated and updated for URL ID 47226.6.\n",
            "Extracted text saved to extracted_text/text_47226.6.txt\n",
            "Scores calculated and updated for URL ID 47688.4.\n",
            "Extracted text saved to extracted_text/text_47688.4.txt\n",
            "Scores calculated and updated for URL ID 48150.2.\n",
            "Extracted text saved to extracted_text/text_48150.2.txt\n",
            "Scores calculated and updated for URL ID 48612.0.\n",
            "Extracted text saved to extracted_text/text_48612.0.txt\n",
            "Scores calculated and updated for URL ID 49073.8.\n",
            "Extracted text saved to extracted_text/text_49073.8.txt\n",
            "Scores calculated and updated for URL ID 49535.6.\n",
            "Extracted text saved to extracted_text/text_49535.6.txt\n",
            "Scores calculated and updated for URL ID 49997.4.\n",
            "Extracted text saved to extracted_text/text_49997.4.txt\n",
            "Scores calculated and updated for URL ID 50459.2.\n",
            "Extracted text saved to extracted_text/text_50459.2.txt\n",
            "Scores calculated and updated for URL ID 50921.0.\n",
            "Extracted text saved to extracted_text/text_50921.0.txt\n",
            "Scores calculated and updated for URL ID 51382.8.\n",
            "Extracted text saved to extracted_text/text_51382.8.txt\n",
            "Scores calculated and updated for URL ID 51844.6.\n",
            "Extracted text saved to extracted_text/text_51844.6.txt\n",
            "Scores calculated and updated for URL ID 52306.4.\n",
            "Extracted text saved to extracted_text/text_52306.4.txt\n",
            "Scores calculated and updated for URL ID 52768.2.\n",
            "Extracted text saved to extracted_text/text_52768.2.txt\n",
            "Results saved to output.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v5xh8fMDPQuv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}